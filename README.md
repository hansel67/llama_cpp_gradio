# llama_cpp_gradio

**Description:**  
This is a simple implementation of Llama.cpp, a local LLM, using the gradio webui python library. Simply install the python packages, download the GGUF models from llama.meta.com, and run the app using:

```
python app.py
```
